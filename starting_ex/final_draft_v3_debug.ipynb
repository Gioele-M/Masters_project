{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import os\n",
    "from sys import stderr, stdout\n",
    "import tempfile\n",
    "import subprocess\n",
    "from warnings import catch_warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO, SeqRecord, Seq, SearchIO, AlignIO, Phylo\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "import Bio.Entrez\n",
    "from Bio.Phylo.TreeConstruction import DistanceCalculator,DistanceTreeConstructor\n",
    "import logging\n",
    "import traceback\n",
    "from pandas.core.frame import DataFrame\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "#Function to open fasta file of imput\n",
    "def open_fasta(filename) -> SeqRecord:\n",
    "    with open(filename) as handle:\n",
    "        sequence_record = SeqIO.read(handle, 'fasta')\n",
    "    return sequence_record\n",
    "\n",
    "\n",
    "#Function to run BLAST with taxid list\n",
    "def blastp_with_list(sequence, list_taxid = [], query_size = 200):\n",
    "    result_handler, result_storer = None, None\n",
    "    #If list is empty run query without specific taxid\n",
    "    if len(list_taxid) <1:\n",
    "        result_handler = NCBIWWW.qblast('blastp', 'nr', sequence, hitlist_size=query_size)\n",
    "        result_storer = result_handler.read()\n",
    "    #Prepare string of Entrez and parse it to qblast\n",
    "    else:\n",
    "        entrez_query = ''\n",
    "        for taxid in list_taxid:\n",
    "            entrez_query += f'txid{taxid}[ORGN]'\n",
    "            if taxid != list_taxid[-1]:\n",
    "                entrez_query += ' OR '\n",
    "        result_handler = NCBIWWW.qblast('blastp', 'nr', sequence, entrez_query= entrez_query, hitlist_size=query_size)\n",
    "        result_storer = result_handler.read()\n",
    "    return result_storer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Efetch to dictionary parser\n",
    "def efetch_protein_to_dictionary(list_of_efetch):\n",
    "    #Declare new dictionary\n",
    "    dictionary = {'Accession':[],'Protein_ID':[], 'Taxid':[], 'Organism_name':[], 'Description':[], 'Seq_length':[], 'Prot_sequence':[]}\n",
    "    for wrapper in list_of_efetch:\n",
    "        try:\n",
    "            #Cast into dictionary to avoid random exception\n",
    "            result = dict(wrapper[0])\n",
    "            acc_ver = result['TSeq_accver']\n",
    "            accession = acc_ver.split('.')\n",
    "            dictionary['Accession'].append(accession[0])\n",
    "            dictionary['Protein_ID'].append(result['TSeq_accver'])\n",
    "            dictionary['Taxid'].append(result['TSeq_taxid'])\n",
    "            dictionary['Organism_name'].append(result['TSeq_orgname'])\n",
    "            dictionary['Description'].append(result['TSeq_defline'])\n",
    "            dictionary['Seq_length'].append(result['TSeq_length'])\n",
    "            dictionary['Prot_sequence'].append(result['TSeq_sequence'])\n",
    "        except KeyError:\n",
    "            print('Could not parse one sequence from efetch \\n')\n",
    "\n",
    "    return dictionary"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def get_fasta_from_accession(accession, email):\n",
    "\n",
    "    #Get the efetch handler \n",
    "    Bio.Entrez.email = email\n",
    "    handler = Bio.Entrez.efetch(db='protein', id=accession, rettype = 'fasta',retmode = 'xml', retmax=1) #Returns JSON regardless\n",
    "    query_protein_efetch = Bio.Entrez.read(handler, 'text')#Returns nested lists and dictionaries \n",
    "    \n",
    "    #Make a dictionary\n",
    "    dictionary_query = efetch_protein_to_dictionary([query_protein_efetch])\n",
    "\n",
    "    #Make and save fasta file \n",
    "    fasta_string_query = f\">{dictionary_query['Accession'][0]} \\n {dictionary_query['Prot_sequence'][0]}\"\n",
    "\n",
    "    fasta_file_name = f\"{dictionary_query['Accession'][0]}_sequence.fasta\"\n",
    "    with open(fasta_file_name, 'w') as handle:\n",
    "        handle.write(fasta_string_query)\n",
    "\n",
    "    fasta_record_q = open_fasta(fasta_file_name)\n",
    "    return fasta_record_q"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def open_input(input, email):\n",
    "    #Declare\n",
    "    protein_sequence = None\n",
    "    if input.endswith('.fas') or input.endswith('.fasta'):\n",
    "        sequence = open_fasta(input)\n",
    "        try: \n",
    "            protein_sequence = sequence.translate(to_stop = True)\n",
    "            logging.info('Nucleotide sequence was translated to protein')\n",
    "        except Exception:\n",
    "            protein_sequence = sequence\n",
    "            logging.info('Protein sequence was opened')\n",
    "    else:\n",
    "        try:\n",
    "            protein_sequence = get_fasta_from_accession(input, email)\n",
    "            logging.info('Protein sequence was retrieved from NCBI protein database')\n",
    "        except Exception as e:\n",
    "            logging.error(traceback.format_exc())\n",
    "\n",
    "    return protein_sequence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def xml_string_to_handler(string):\n",
    "    #make temporary file\n",
    "    tmp = tempfile.NamedTemporaryFile(mode='a+')\n",
    "    #write string\n",
    "    tmp.write(string)\n",
    "    handler = SearchIO.read(tmp.name, 'blast-xml')\n",
    "    tmp.close()\n",
    "    return handler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "#Creation of a dictionary with all HSPS\n",
    "def blast_to_dictionary(blastresult):\n",
    "    blast_dictionary = {'ID' : [], 'Description' : [], 'Seq_length' : [], 'Accession' : [], 'Bitscore' : [], 'Evalue' : [], 'Tot_aln_span':[], 'Identity' :[]}\n",
    "    #Loop through results \n",
    "    for result in blastresult:\n",
    "        blast_dictionary['ID'].append(result.id)\n",
    "        blast_dictionary['Description'].append(result.description)\n",
    "        blast_dictionary['Seq_length'].append(result.seq_len)\n",
    "        blast_dictionary['Accession'].append(result.accession)\n",
    "        #Store results of first HSP\n",
    "        first_hsp = result.hsps[0]\n",
    "        blast_dictionary['Bitscore'].append(first_hsp.bitscore)\n",
    "        blast_dictionary['Evalue'].append(first_hsp.evalue)\n",
    "        #Create variables to store results of multiple hsps\n",
    "        all_alnspan, all_gapnum = [],[] \n",
    "        #Collect data of all hsps for each hit\n",
    "        for hsp in result.hsps:\n",
    "            all_alnspan.append(int(hsp.aln_span))\n",
    "            all_gapnum.append(int(hsp.gap_num))\n",
    "        #Calculate total alignment span and gaps to calculate identity\n",
    "        tot_alnspan, tot_gapnum = int(), int()\n",
    "        seq_len = int(result.seq_len) #DOUBLE CHECK \n",
    "        for span in all_alnspan:\n",
    "            tot_alnspan += span\n",
    "        for gap in all_gapnum:\n",
    "            tot_gapnum += gap\n",
    "        identity = (tot_alnspan - tot_gapnum)/seq_len*100\n",
    "        blast_dictionary['Tot_aln_span'].append(tot_alnspan)\n",
    "        blast_dictionary['Identity'].append(round(identity, 3))\n",
    "    return blast_dictionary"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "!conda init --help"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "usage: conda init [-h] [--all] [--reverse] [--json] [-v] [-q] [-d]\n",
      "                  [shells ...]\n",
      "\n",
      "Initialize conda for shell interaction. [Experimental]\n",
      "\n",
      "Options:\n",
      "\n",
      "positional arguments:\n",
      "  shells         One or more shells to be initialized. If not given, the\n",
      "                 default value is 'bash' on unix and 'cmd.exe' on Windows. Use\n",
      "                 the '--all' flag to initialize all shells. Currently\n",
      "                 compatible shells are {bash, fish, powershell, tcsh, xonsh,\n",
      "                 zsh}\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help     Show this help message and exit.\n",
      "  --all          Initialize all currently available shells.\n",
      "  -d, --dry-run  Only display what would have been done.\n",
      "\n",
      "setup type:\n",
      "  --reverse      Undo past effects of conda init.\n",
      "\n",
      "Output, Prompt, and Flow Control Options:\n",
      "  --json         Report all output as json. Suitable for using conda\n",
      "                 programmatically.\n",
      "  -v, --verbose  Use once for info, twice for debug, three times for trace.\n",
      "  -q, --quiet    Do not display progress bar.\n",
      "\n",
      "Key parts of conda's functionality require that it interact directly with the shell\n",
      "within which conda is being invoked. The `conda activate` and `conda deactivate` commands\n",
      "specifically are shell-level commands. That is, they affect the state (e.g. environment\n",
      "variables) of the shell context being interacted with. Other core commands, like\n",
      "`conda create` and `conda install`, also necessarily interact with the shell environment.\n",
      "They're therefore implemented in ways specific to each shell. Each shell must be configured\n",
      "to make use of them.\n",
      "\n",
      "This command makes changes to your system that are specific and customized for each shell.\n",
      "To see the specific files and locations on your system that will be affected before, use the\n",
      "'--dry-run' flag.  To see the exact changes that are being or will be made to each location,\n",
      "use the '--verbose' flag.\n",
      "\n",
      "IMPORTANT: After running `conda init`, most shells will need to be closed and restarted\n",
      "           for changes to take effect.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from ete3 import Tree\n",
    "t = Tree( \"((a,b),c);\" )\n",
    "t.render(\"mytree.png\", w=183, units=\"mm\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'faces': [[625.3847069843147,\n",
       "   42.78947995155837,\n",
       "   645.1336977311878,\n",
       "   82.28746144530456,\n",
       "   3,\n",
       "   'b'],\n",
       "  [625.3847069843147,\n",
       "   3.291498457812182,\n",
       "   645.1336977311878,\n",
       "   42.78947995155837,\n",
       "   2,\n",
       "   'a'],\n",
       "  [319.27535040778173,\n",
       "   82.28746144530456,\n",
       "   335.7328426968426,\n",
       "   121.78544293905074,\n",
       "   4,\n",
       "   'c']],\n",
       " 'node_areas': {0: [3.2914984578121826,\n",
       "   3.291498457812182,\n",
       "   645.1336977311878,\n",
       "   121.78544293905074],\n",
       "  1: [13.16599383124873,\n",
       "   3.291498457812182,\n",
       "   645.1336977311878,\n",
       "   82.28746144530456],\n",
       "  2: [319.27535040778173,\n",
       "   3.291498457812182,\n",
       "   645.1336977311878,\n",
       "   42.78947995155837],\n",
       "  3: [319.27535040778173,\n",
       "   42.78947995155837,\n",
       "   645.1336977311878,\n",
       "   82.28746144530456],\n",
       "  4: [13.16599383124873,\n",
       "   82.28746144530456,\n",
       "   335.7328426968426,\n",
       "   121.78544293905074]},\n",
       " 'nodes': [[307.7551058054391,\n",
       "   36.206483035934006,\n",
       "   320.9210996366878,\n",
       "   49.37247686718273,\n",
       "   1,\n",
       "   None],\n",
       "  [613.8644623819721,\n",
       "   55.9554737828071,\n",
       "   627.0304562132208,\n",
       "   69.12146761405583,\n",
       "   3,\n",
       "   None],\n",
       "  [1.6457492289060913,\n",
       "   65.82996915624365,\n",
       "   14.811743060154821,\n",
       "   78.99596298749238,\n",
       "   0,\n",
       "   None],\n",
       "  [613.8644623819721,\n",
       "   16.457492289060912,\n",
       "   627.0304562132208,\n",
       "   29.62348612030964,\n",
       "   2,\n",
       "   None],\n",
       "  [307.7551058054391,\n",
       "   95.45345527655329,\n",
       "   320.9210996366878,\n",
       "   108.61944910780201,\n",
       "   4,\n",
       "   None]]}"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "fasta_record = open_input('XP_011809449', 'A.N.Other@example.com')\n",
    "fasta_record"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SeqRecord(seq=Seq('MVLSEVDVVKADPAAASHPLLLNGDADVAQKSPGSVAENNLCSQYEEKVRPCID...FPG'), id='XP_011809449', name='XP_011809449', description='XP_011809449', dbxrefs=[])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "blast_handler = blastp_with_list(fasta_record.seq, [])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "blast_result = xml_string_to_handler(blast_handler)\n",
    "len(blast_result)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "dictionary_blast = blast_to_dictionary(blast_result)\n",
    "print(len(dictionary_blast['ID']))\n",
    "\n",
    "\n",
    "blast_df = pd.DataFrame.from_dict(dictionary_blast)\n",
    "len(blast_df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "200\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "version": "3.5.6",
   "pygments_lexer": "ipython3",
   "name": "python",
   "codemirror_mode": {
    "version": 3,
    "name": "ipython"
   },
   "mimetype": "text/x-python",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.5.6 64-bit ('ete3_2': conda)"
  },
  "interpreter": {
   "hash": "42fe78aebb72ae4ffa9c0879ec3daa3a9473ae9ee57e2d93cd6d9a5311e615e3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}